{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOokAV1ImFZzTiUTCwZE61g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aryu-Tamura/GoogleColab_ChatbotTest/blob/main/03_%E8%8B%B1%E4%BC%9A%E8%A9%B1%E3%83%81%E3%83%A3%E3%83%83%E3%83%88%E3%83%9C%E3%83%83%E3%83%88_MVP3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**MVP3: 音声での対話機能**\n",
        "\n",
        "目的: テキスト入力に加えて、音声でAIと対話し、AIの応答を音声で聞けるようにします。\n",
        "\n",
        "（エラー処理などを省略したシンプルな構成）\n",
        "\n",
        "手順:\n",
        "\n",
        "1. 必要なライブラリをインストールします。\n",
        "2. ライブラリを読み込みます。\n",
        "3. OpenAI APIキーを設定します。\n",
        "4. 会話履歴を保存する変数 (`history`) を準備します。\n",
        "5. 音声認識関数を作成します。\n",
        "6. 音声合成関数を作成します。\n",
        "7. メイン関数を作成します。\n",
        "8. Gradioを使って、シンプルなWebアプリのUIを作ります (`Interface` を使用)。\n",
        "9. Webアプリを起動します。\n",
        "\n",
        "--------------------\n",
        "\n",
        "\n",
        "1. ライブラリのインストール"
      ],
      "metadata": {
        "id": "2_mrjLDdDYx9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vay_6HkGBncq"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------\n",
        "\n",
        "2. ライブラリのインポート\n",
        "\n"
      ],
      "metadata": {
        "id": "pBg-a33zD7mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "import os\n",
        "import datetime"
      ],
      "metadata": {
        "id": "txO1OJV8Dv_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------\n",
        "\n",
        "\n",
        "3. OpenAI APIキーの設定\n",
        "\n",
        "※事前にColabの左メニュー(🔑)で `OPENAI_API_KEY` という名前でAPIキーを設定しておいてください。\n",
        "\n"
      ],
      "metadata": {
        "id": "aomTPdMgEBKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata # APIキーを安全に読み込むため\n",
        "key = userdata.get('OPENAI_API_KEY')\n",
        "client = openai.OpenAI(api_key=key)"
      ],
      "metadata": {
        "id": "s05R0y0VEDAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------\n",
        "\n",
        "4. 会話履歴 (`history`) の準備\n",
        "\n",
        "※このセルはノートブックを開いて最初に一度だけ実行します。"
      ],
      "metadata": {
        "id": "u__87NoJEEcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# グローバル変数として会話履歴を初期化\n",
        "history = [] # まず空のリストを作成\n",
        "\n",
        "# AIへの指示（システムプロンプト）を定義\n",
        "system_prompt = \"\"\"あなたは、ユーザーと自然で流暢な英会話を行うAI英語教師です。\n",
        "\n",
        "# あなたの役割\n",
        "- ユーザーの英語力向上のために、自然で日常的な英会話を行ってください。\n",
        "- ユーザーの英語表現や文法に間違いがあれば、会話の流れを止めないように、自然な形で指摘し、より適切な表現を提案してください。\n",
        "- ユーザーの質問や発言には、共感的に、そして前向きな態度で応答してください。\n",
        "\n",
        "# 回答の形式\n",
        "- 会話は常に英語で行ってください。日本語で応答してはいけません。\n",
        "- 回答は、原則として短く（1～3文程度）、自然な口語表現を使ってください。\n",
        "- ユーザーが文法や表現のミスをした場合は、以下のような形式で訂正例を示してください。\n",
        "  例 (Example): User: \"I goed to park yesterday.\" AI: \"Oh, nice! You mean, 'I went to the park yesterday,' right?\"\n",
        "\n",
        "# 入出力の例 (Input/Output Examples)\n",
        "User: \"Hello! How was your day?\" AI: \"Hey! My day's going great, thanks for asking. How about you?\"\n",
        "User: \"I'm study English today.\" AI: \"That's great! Just a quick tip: you'd say, 'I'm studying English today.' What are you working on right now?\"\n",
        "User: \"Can you help me about grammar?\" AI: \"Of course! I'd say, 'Can you help me with grammar?' Sure thing! What grammar point do you want to talk about?\" \"\"\"\n",
        "\n",
        "# historyリストの最初にシステムプロンプトを追加\n",
        "history.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "\n",
        "print(\"会話履歴(history)を初期化しました。\")"
      ],
      "metadata": {
        "id": "YMw4N2fREQ5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------\n",
        "\n",
        "5. 音声認識関数\n",
        "\n"
      ],
      "metadata": {
        "id": "Bg6L9QxuEYMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def speech_to_text_simple(audio_filepath):\n",
        "    \"\"\"簡単な音声認識関数 (Whisper)\"\"\"\n",
        "    if audio_filepath is None:\n",
        "        return \"\"\n",
        "    audio_file = open(audio_filepath, \"rb\")\n",
        "    transcription = client.audio.transcriptions.create(\n",
        "        model=\"whisper-1\",\n",
        "        file=audio_file\n",
        "    )\n",
        "    return transcription.text"
      ],
      "metadata": {
        "id": "_IYasKmREZmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------\n",
        "\n",
        "6. 音声合成関数\n",
        "\n"
      ],
      "metadata": {
        "id": "4aiiMOsXEdBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_speech_simple(text, output_dir=\"tts_output_simple\"):\n",
        "    \"\"\"簡単な音声合成関数 (OpenAI TTS)\"\"\"\n",
        "    if not text:\n",
        "        return None\n",
        "    try: # 簡単なエラー処理のみ\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        speech_file_path = os.path.join(output_dir, f\"response_{timestamp}.mp3\")\n",
        "        response = client.audio.speech.create(\n",
        "            model=\"tts-1\",\n",
        "            voice=\"alloy\",\n",
        "            input=text\n",
        "        )\n",
        "        response.stream_to_file(speech_file_path)\n",
        "        return speech_file_path\n",
        "    except Exception as e:\n",
        "        print(f\"音声合成エラー: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "vvtOZWrrEchJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------\n",
        "\n",
        "7. シンプルなメイン関数"
      ],
      "metadata": {
        "id": "NLpWrxr6EnZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def english_teacher_bot_simple_voice(input_mode, input_text, input_audio):\n",
        "    \"\"\"\n",
        "    入力モードに応じて処理し、応答テキストと音声パスを返すシンプルな関数。\n",
        "    戻り値: (実際に使われた入力テキスト, AI応答テキスト, AI応答音声パス)\n",
        "    \"\"\"\n",
        "    global history\n",
        "\n",
        "    # 1. 入力モードに応じてテキスト化\n",
        "    processed_input_text = \"\"\n",
        "    if input_mode == \"Text\":\n",
        "        processed_input_text = input_text\n",
        "    elif input_mode == \"Voice\" and input_audio is not None:\n",
        "        processed_input_text = speech_to_text_simple(input_audio)\n",
        "    else: # Voiceモードで音声がない場合などは空文字\n",
        "        processed_input_text = \"\"\n",
        "\n",
        "    print(f\"処理された入力テキスト: {processed_input_text}\")\n",
        "\n",
        "    # 有効な入力がない場合は終了\n",
        "    if not processed_input_text:\n",
        "        return \"(入力なし)\", \"(入力がなかったため応答できません)\", None\n",
        "\n",
        "    # 2. ユーザー入力を履歴に追加\n",
        "    history.append({\"role\": \"user\", \"content\": processed_input_text})\n",
        "\n",
        "    # 3. ChatGPT API呼び出し\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=history,\n",
        "            max_tokens=100,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        assistant_response_text = response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"ChatGPT APIエラー: {e}\")\n",
        "        assistant_response_text = f\"エラー: {e}\"\n",
        "        history.pop() # エラー時はユーザー入力を履歴から削除\n",
        "\n",
        "    # 4. AI応答を履歴に追加\n",
        "    history.append({\"role\": \"assistant\", \"content\": assistant_response_text})\n",
        "    print(f\"AI応答テキスト: {assistant_response_text}\")\n",
        "\n",
        "    # 5. 音声合成\n",
        "    response_audio_path = None\n",
        "    if not assistant_response_text.startswith(\"エラー\"): # エラーメッセージは読み上げない\n",
        "        response_audio_path = text_to_speech_simple(assistant_response_text)\n",
        "\n",
        "    # 6. 結果を返す (入力テキスト, 応答テキスト, 応答音声パス)\n",
        "    return processed_input_text, assistant_response_text, response_audio_path\n",
        "\n",
        "print(\"関数 'english_teacher_bot_simple_voice' を定義しました。\")"
      ],
      "metadata": {
        "id": "S-6NPXqJEqJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------\n",
        "\n",
        "8. Gradio Interface 作成\n",
        "\n"
      ],
      "metadata": {
        "id": "QIcccdzoEtC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# gr.Interface を使ってUIを作成します\n",
        "bot_interface = gr.Interface(\n",
        "    fn=english_teacher_bot_simple_voice, # 作成したメイン関数\n",
        "    # 入力コンポーネントをリストで指定 (順番が重要)\n",
        "    inputs=[\n",
        "        gr.Radio([\"Text\", \"Voice\"], label=\"入力方法\", value=\"Text\"),\n",
        "        gr.Textbox(label=\"テキスト入力\", placeholder=\"テキストを入力するか、下で録音\"),\n",
        "        gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"音声入力\")\n",
        "    ],\n",
        "    # 出力コンポーネントをリストで指定 (順番が重要)\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"認識された/入力されたテキスト\"), # 戻り値1 (processed_input_text)\n",
        "        gr.Textbox(label=\"AIの応答テキスト\"),          # 戻り値2 (assistant_response_text)\n",
        "        gr.Audio(label=\"AIの応答音声\", type=\"filepath\") # 戻り値3 (response_audio_path)\n",
        "    ],\n",
        "    title=\"英会話チャットボット\",\n",
        "    description=\"テキストまたは音声で入力してください。\"\n",
        ")\n",
        "\n",
        "print(\"Gradioインターフェースを作成しました。\")"
      ],
      "metadata": {
        "id": "KnHYXRSREuFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------\n",
        "\n",
        "9. Webアプリの起動\n",
        "\n"
      ],
      "metadata": {
        "id": "A05hyxSkEx6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 作成したUIを起動します\n",
        "bot_interface.launch(share=True)"
      ],
      "metadata": {
        "id": "KhLjkoXGEzjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------\n",
        "\n",
        "これで、シンプルな構成のMVP3が完成しました。gr.Interface を使用し、音声認識・合成関数やメイン関数も簡略化されています。エラーハンドリングは最小限ですが、基本的な音声入出力の動作を確認できるはずです。"
      ],
      "metadata": {
        "id": "O4r6fwaGE6MU"
      }
    }
  ]
}